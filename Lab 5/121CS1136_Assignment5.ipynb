{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('DelhiAQI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = dataset.dropna()\n",
    "for i in dataSet.columns:\n",
    "    if i != 'AQI':\n",
    "        dataSet[i] = (dataSet[i] - dataSet[i].mean()) / (dataSet[i].std())\n",
    "x = dataSet.drop('AQI', axis = 1)\n",
    "y = dataSet['AQI'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 24489.2441 - val_loss: 3203.0957\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3232.0947 - val_loss: 3071.1687\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3115.3020 - val_loss: 2977.6670\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3065.9846 - val_loss: 2904.0859\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3014.4788 - val_loss: 2899.5879\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2986.8000 - val_loss: 2861.4678\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2941.3560 - val_loss: 2831.6914\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2897.4492 - val_loss: 2793.0593\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2859.7131 - val_loss: 2744.9087\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2832.1465 - val_loss: 2727.3730\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2813.3367 - val_loss: 2713.4844\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2772.6340 - val_loss: 2711.3958\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2755.8218 - val_loss: 2738.8076\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2735.4966 - val_loss: 2677.2649\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2713.2134 - val_loss: 2649.7886\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2691.1716 - val_loss: 2785.6965\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2680.9761 - val_loss: 2695.4182\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2657.9922 - val_loss: 2640.6631\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2644.9766 - val_loss: 2644.9155\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2641.0212 - val_loss: 2672.1331\n",
      "94/94 [==============================] - 0s 882us/step\n",
      "MSE: 2877.0986666666668\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 13411.6748 - val_loss: 3172.9368\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3219.0515 - val_loss: 3011.9680\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3107.7129 - val_loss: 3017.1572\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3047.6104 - val_loss: 2950.8904\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3006.2295 - val_loss: 2851.2866\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2972.0793 - val_loss: 2826.2839\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2932.3965 - val_loss: 2815.2866\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2910.7141 - val_loss: 2836.5703\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2884.0176 - val_loss: 2905.6357\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2848.5105 - val_loss: 2731.9019\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2813.4351 - val_loss: 2735.1326\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2797.8425 - val_loss: 2686.5164\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2774.7664 - val_loss: 2722.7251\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2748.7512 - val_loss: 2843.0427\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2735.7766 - val_loss: 2655.0994\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2732.0146 - val_loss: 2646.8418\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2708.3665 - val_loss: 2665.3547\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2697.7234 - val_loss: 2657.4404\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2666.7188 - val_loss: 2640.8010\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2673.2539 - val_loss: 2600.2537\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "MSE: 2835.4306666666666\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 10048.1768 - val_loss: 3087.7444\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3199.2217 - val_loss: 3009.0623\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3119.2898 - val_loss: 3075.0273\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3058.2529 - val_loss: 3053.3496\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3029.0427 - val_loss: 2932.6743\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2963.1125 - val_loss: 3029.9751\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2929.1521 - val_loss: 2833.4456\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2902.5222 - val_loss: 2799.4553\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2861.4756 - val_loss: 2794.9788\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2824.8552 - val_loss: 2729.1509\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2793.4592 - val_loss: 2741.2097\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2773.4839 - val_loss: 2771.1367\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2753.0452 - val_loss: 2728.2256\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2740.1248 - val_loss: 2723.4185\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2711.4072 - val_loss: 2670.8801\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2699.0891 - val_loss: 2713.0732\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2692.0728 - val_loss: 2792.1396\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2685.3728 - val_loss: 2672.0293\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2662.9072 - val_loss: 2628.2400\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2667.3950 - val_loss: 2687.8345\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "MSE: 2847.6516666666666\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 13545.2256 - val_loss: 3197.6963\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3223.1665 - val_loss: 2988.7739\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3116.9751 - val_loss: 2961.3760\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3062.6819 - val_loss: 2900.9177\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3016.3901 - val_loss: 2937.6963\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2967.3621 - val_loss: 2873.5063\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2922.2131 - val_loss: 2815.0623\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2882.1140 - val_loss: 2842.3604\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2863.1038 - val_loss: 2854.7356\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2842.4009 - val_loss: 2802.3997\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2825.4868 - val_loss: 2751.0684\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2783.0098 - val_loss: 2901.1499\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2779.2693 - val_loss: 2742.0781\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2738.8765 - val_loss: 2696.4431\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2729.0564 - val_loss: 2695.2974\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2712.5166 - val_loss: 2710.9666\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2708.0012 - val_loss: 2744.9619\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2694.9663 - val_loss: 2673.3359\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2678.7932 - val_loss: 2700.2034\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2654.4368 - val_loss: 2646.3879\n",
      "94/94 [==============================] - 0s 947us/step\n",
      "MSE: 2808.5176666666666\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 10850.6777 - val_loss: 3244.0952\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3209.7517 - val_loss: 2997.1943\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3108.2852 - val_loss: 2970.3589\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3056.7200 - val_loss: 2977.9487\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3019.1050 - val_loss: 2957.1772\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2975.7439 - val_loss: 3004.7903\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2917.4839 - val_loss: 2912.8643\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2895.5940 - val_loss: 2752.8796\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2863.9775 - val_loss: 2783.2529\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2812.1646 - val_loss: 2784.3367\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2803.7661 - val_loss: 2741.3489\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2774.4409 - val_loss: 2895.8213\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2755.1890 - val_loss: 2742.5522\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2742.2349 - val_loss: 2733.1187\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2718.3545 - val_loss: 2687.6545\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2705.0876 - val_loss: 2727.4702\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2692.3413 - val_loss: 2678.0186\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2671.2805 - val_loss: 2658.8293\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2665.6064 - val_loss: 2606.7502\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2651.1147 - val_loss: 2580.2629\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "MSE: 2801.2006666666666\n",
      "Average MSE: 2833.979866666667\n"
     ]
    }
   ],
   "source": [
    "#  Add a fully connected layer with 32 neurons with sigmoid activation and glorot uniform kernel initializer.\n",
    "#  Add a fully connected layer layer with 16 neurons, relu activation and he uniform as kernel initializer. \n",
    "#  Add a fully a connected layer with ] neuron, relu activation function and he uniform as kernel initializer. \n",
    "#  Use Adam optimizer with batch size 16, learning rate 0.01 and epochs set to 20.\n",
    "\n",
    "def model1(x_train, x_val, y_train, y_val):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation = 'sigmoid', kernel_initializer = 'glorot_uniform'))\n",
    "    model.add(Dense(16, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model.add(Dense(1, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model.compile(optimizer = Adam(learning_rate = 0.01), loss = 'mean_squared_error')\n",
    "    model.fit(x_train, y_train, batch_size = 16, epochs = 20, validation_data = (x_val, y_val))\n",
    "    return model\n",
    "\n",
    "count = 5\n",
    "avg_mse = 0\n",
    "for i in range(count):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.25, random_state = 42)\n",
    "    model = model1(x_train, x_val, y_train, y_val)\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.round(y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    avg_mse += mse\n",
    "    print('MSE:', mse)\n",
    "print('Average MSE:', avg_mse/count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 69392.6406 - val_loss: 50657.1992\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 39403.9531 - val_loss: 28324.6426\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 22277.0801 - val_loss: 16134.6904\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 13347.3672 - val_loss: 9656.1211\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 8051.7031 - val_loss: 6164.1860\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 5515.6450 - val_loss: 4480.5068\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 4338.4961 - val_loss: 3808.3450\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3788.0232 - val_loss: 3491.0483\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3487.6472 - val_loss: 3400.2173\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 3306.2317 - val_loss: 3165.8943\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 3135.6753 - val_loss: 3063.8867\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 3003.5095 - val_loss: 3004.0940\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2925.4773 - val_loss: 2910.4946\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2844.7334 - val_loss: 2819.6416\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2782.9399 - val_loss: 2835.8118\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2743.6501 - val_loss: 2823.4824\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2698.1702 - val_loss: 2724.5962\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2662.2744 - val_loss: 2708.2913\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2639.0190 - val_loss: 2685.8408\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 2609.9370 - val_loss: 2694.1152\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "MSE: 2948.920666666667\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 68150.3281 - val_loss: 50232.2578\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 39252.5781 - val_loss: 28345.7617\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 22328.7070 - val_loss: 15929.0508\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 12038.9443 - val_loss: 8151.7500\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 6818.8677 - val_loss: 5242.5938\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 4805.1963 - val_loss: 4058.0747\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3981.8872 - val_loss: 3634.0183\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3577.9617 - val_loss: 3336.7974\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3304.2419 - val_loss: 3135.6699\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3130.9893 - val_loss: 2991.7917\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2998.0613 - val_loss: 2912.6824\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2913.0051 - val_loss: 2811.8821\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2855.5754 - val_loss: 2868.7400\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2799.5757 - val_loss: 2761.2046\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2742.8245 - val_loss: 2824.2510\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2703.6021 - val_loss: 2762.8257\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2669.6838 - val_loss: 2633.4331\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2639.2944 - val_loss: 2685.6045\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2597.8049 - val_loss: 2608.6250\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2579.7241 - val_loss: 2670.0762\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "MSE: 2927.458\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 70246.5625 - val_loss: 54451.3164\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 44181.1094 - val_loss: 33438.0898\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 27062.4688 - val_loss: 20211.9902\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 16823.3594 - val_loss: 12976.6123\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 10714.6777 - val_loss: 7988.6826\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 7000.2251 - val_loss: 5533.5049\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 5141.5225 - val_loss: 4310.1387\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 4247.4395 - val_loss: 3774.9807\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3813.8813 - val_loss: 3497.0000\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3544.0977 - val_loss: 3334.8884\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3319.0322 - val_loss: 3147.7681\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3149.9822 - val_loss: 3037.4814\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3026.8079 - val_loss: 2945.1704\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2958.7236 - val_loss: 2954.4187\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2901.4573 - val_loss: 2865.0393\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2838.8228 - val_loss: 2882.7854\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2784.6531 - val_loss: 2796.6370\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2733.8523 - val_loss: 2758.7383\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2718.7075 - val_loss: 2765.8882\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2680.5723 - val_loss: 2769.4978\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "MSE: 2966.337666666667\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 69353.1172 - val_loss: 50210.9766\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 38838.9492 - val_loss: 27811.3047\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 21859.8672 - val_loss: 15842.2988\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 13003.7959 - val_loss: 9330.0820\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 7865.7207 - val_loss: 6004.6406\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 5421.9814 - val_loss: 4437.7559\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 4278.3735 - val_loss: 3806.6187\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3744.3230 - val_loss: 3428.4897\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3441.4065 - val_loss: 3288.4534\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3226.8013 - val_loss: 3178.8091\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 3081.8132 - val_loss: 3037.0840\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 2985.5823 - val_loss: 2948.4126\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2923.9248 - val_loss: 2959.2700\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2883.0134 - val_loss: 2874.8994\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2852.2161 - val_loss: 2917.8752\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2816.9910 - val_loss: 2868.1797\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 2788.0586 - val_loss: 2750.0330\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 2757.0369 - val_loss: 2780.0659\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2735.6743 - val_loss: 2726.6799\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2698.0945 - val_loss: 2727.4819\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "MSE: 2992.367333333333\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 5s 3ms/step - loss: 88622.5078 - val_loss: 87336.4844\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.4766 - val_loss: 87336.4844\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 88622.5938 - val_loss: 87336.4844\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6328 - val_loss: 87336.4844\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5078 - val_loss: 87336.4844\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5859 - val_loss: 87336.4844\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5234 - val_loss: 87336.4844\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6094 - val_loss: 87336.4844\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5234 - val_loss: 87336.4844\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.4922 - val_loss: 87336.4844\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6172 - val_loss: 87336.4844\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6172 - val_loss: 87336.4844\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5781 - val_loss: 87336.4844\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5703 - val_loss: 87336.4844\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 88622.4531 - val_loss: 87336.4844\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 88622.5078 - val_loss: 87336.4844\n",
      "282/282 [==============================] - 1s 3ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "MSE: 9324.854\n",
      "Average MSE: 4231.987533333333\n"
     ]
    }
   ],
   "source": [
    "# Add a fully connected layer with 32 neurons with sigmoid activation and glorot uniform kernel initializer. \n",
    "# Add a fully connected layer layer with 8 a neurons, sigmoid activation and glorot normal as kernel initializer.\n",
    "# Add a fully a connected layer ith neuron, relu activation function and he uniform as kernel initializer. \n",
    "# Use Adam optimizer with batch size 8. learning rate 0.01 and epochs set to 20. \n",
    "# Extract the features from second last fully connected layer (having 8 neurons) and model it using a Support Vector regressor.\n",
    "\n",
    "from keras.models import Model\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def model2(x_train, x_val, y_train, y_val):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation = 'sigmoid', kernel_initializer = 'glorot_uniform'))\n",
    "    model.add(Dense(8, activation = 'sigmoid', kernel_initializer = 'glorot_normal'))\n",
    "    model.add(Dense(1, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model.compile(optimizer = Adam(learning_rate = 0.01), loss = 'mean_squared_error')\n",
    "    model.fit(x_train, y_train, batch_size = 8, epochs = 20, validation_data = (x_val, y_val))\n",
    "    model = Model(inputs = model.input, outputs = model.get_layer(index = 2).output)\n",
    "    return model\n",
    "\n",
    "count = 5\n",
    "avg_mse = 0\n",
    "for i in range(count):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.25, random_state = 42)\n",
    "    model = model2(x_train, x_val, y_train, y_val)\n",
    "    x_train = model.predict(x_train)\n",
    "    x_val = model.predict(x_val)\n",
    "    x_test = model.predict(x_test)\n",
    "    model = SVR()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.round(y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    avg_mse += mse\n",
    "    print('MSE:', mse)\n",
    "print('Average MSE:', avg_mse/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "563/563 [==============================] - 3s 3ms/step - loss: 12987.1113 - val_loss: 3213.5969\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3237.4939 - val_loss: 3063.9937\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3122.0691 - val_loss: 3095.3091\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3062.7581 - val_loss: 2935.3630\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3010.8396 - val_loss: 2955.5674\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2972.7571 - val_loss: 2869.1362\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2937.1880 - val_loss: 2841.2363\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2904.7166 - val_loss: 2787.0530\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2864.1189 - val_loss: 2819.2288\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2829.3354 - val_loss: 2765.5522\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2815.9106 - val_loss: 2763.9229\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2788.4768 - val_loss: 2737.5344\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2761.8958 - val_loss: 2724.5386\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2747.1150 - val_loss: 2733.0515\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2721.2939 - val_loss: 2717.9387\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2727.0574 - val_loss: 2727.5518\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2700.1260 - val_loss: 2672.5439\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2689.9368 - val_loss: 2674.1973\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2674.9126 - val_loss: 2748.4656\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2665.3325 - val_loss: 2656.9724\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 5s 3ms/step - loss: 67585.3516 - val_loss: 50073.3242\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 39205.4805 - val_loss: 28332.6289\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 22284.0449 - val_loss: 16141.3164\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 13429.7451 - val_loss: 9785.9482\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 8109.0073 - val_loss: 6145.6099\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 5517.1333 - val_loss: 4532.0371\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 4370.2065 - val_loss: 3939.8396\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3874.2979 - val_loss: 3547.3679\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 3532.0710 - val_loss: 3295.5627\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 3330.5037 - val_loss: 3171.7029\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3174.4060 - val_loss: 3067.6853\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3057.5864 - val_loss: 2973.3848\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2950.5752 - val_loss: 2949.5757\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 2898.8779 - val_loss: 2847.2585\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 2846.3289 - val_loss: 2758.5303\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 2797.2104 - val_loss: 2766.0891\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 2758.6436 - val_loss: 2769.8650\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 2720.8823 - val_loss: 2828.3940\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2693.6855 - val_loss: 2719.2419\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 5s 5ms/step - loss: 2678.4634 - val_loss: 2701.8008\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 1s 3ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "MSE: 2840.0396666666666\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 6s 3ms/step - loss: 16234.3486 - val_loss: 3301.6831\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 3294.8154 - val_loss: 3039.7170\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 3149.8467 - val_loss: 2964.9854\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 3070.6306 - val_loss: 2906.0496\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 3023.3574 - val_loss: 2937.4578\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2970.1511 - val_loss: 2868.7346\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2925.2358 - val_loss: 2775.7668\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2907.1582 - val_loss: 2816.8357\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2857.1746 - val_loss: 2825.4473\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2832.9541 - val_loss: 2741.4260\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 8s 14ms/step - loss: 2821.4358 - val_loss: 2744.0706\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2788.4231 - val_loss: 2706.5364\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2766.6565 - val_loss: 2683.5859\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 5s 9ms/step - loss: 2754.4568 - val_loss: 2744.2368\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 2725.8740 - val_loss: 2714.7844\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2712.4255 - val_loss: 2652.9443\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2689.7993 - val_loss: 2637.6309\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2686.2671 - val_loss: 2819.4700\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2669.0403 - val_loss: 2650.7129\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2639.6340 - val_loss: 2623.0806\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 5s 3ms/step - loss: 63613.5234 - val_loss: 42637.1055\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 31047.8965 - val_loss: 20526.3418\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 15786.2188 - val_loss: 10737.6436\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 8575.2236 - val_loss: 6256.4331\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 5453.5586 - val_loss: 4428.6177\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 4250.5527 - val_loss: 3718.5066\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3733.4539 - val_loss: 3404.4971\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 3455.3027 - val_loss: 3252.9097\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 3292.2998 - val_loss: 3153.7886\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3169.3196 - val_loss: 3030.5603\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 12s 11ms/step - loss: 3049.5737 - val_loss: 2974.1443\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2976.6416 - val_loss: 2903.0071\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2918.4983 - val_loss: 2894.6982\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2871.5422 - val_loss: 2844.1667\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 2821.7063 - val_loss: 2822.2900\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2791.4656 - val_loss: 2832.5339\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 2747.1624 - val_loss: 2755.4551\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 2705.4121 - val_loss: 2764.3818\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2691.6272 - val_loss: 2762.7161\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2658.9902 - val_loss: 2741.1724\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 1s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "MSE: 2869.9486666666667\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 10155.0674 - val_loss: 3115.7097\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3192.0403 - val_loss: 3082.0037\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3105.3577 - val_loss: 2942.6077\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3058.5413 - val_loss: 3074.2207\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 3013.6992 - val_loss: 2852.1860\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2965.9578 - val_loss: 2907.2908\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2936.5195 - val_loss: 3034.4041\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2903.1523 - val_loss: 2781.2263\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2855.8157 - val_loss: 2762.6174\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2808.7222 - val_loss: 2759.8567\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2786.1868 - val_loss: 2714.1924\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2755.0386 - val_loss: 2720.1736\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2743.4937 - val_loss: 2706.6572\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2721.8325 - val_loss: 2673.9666\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2710.2981 - val_loss: 2685.3772\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2682.1938 - val_loss: 2655.0132\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2664.9241 - val_loss: 2670.3379\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2642.8123 - val_loss: 2639.6577\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2638.7175 - val_loss: 2623.9912\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2629.7935 - val_loss: 2600.4131\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 4s 2ms/step - loss: 88622.5781 - val_loss: 87336.4844\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5938 - val_loss: 87336.4844\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5234 - val_loss: 87336.4844\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5781 - val_loss: 87336.4844\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.6016 - val_loss: 87336.4844\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5859 - val_loss: 87336.4844\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.4688 - val_loss: 87336.4844\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5078 - val_loss: 87336.4844\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.6016 - val_loss: 87336.4844\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5938 - val_loss: 87336.4844\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 88622.5859 - val_loss: 87336.4844\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "MSE: 2919.423\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 11693.5791 - val_loss: 3217.0916\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3208.3096 - val_loss: 3010.4141\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 3114.4141 - val_loss: 2979.7646\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 3047.9873 - val_loss: 2918.3823\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2996.9380 - val_loss: 2873.3201\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2969.4021 - val_loss: 2840.1990\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2936.6921 - val_loss: 2854.3684\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2896.2205 - val_loss: 2826.0823\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2864.5544 - val_loss: 2843.4463\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2832.6643 - val_loss: 2788.5557\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2811.7690 - val_loss: 2765.3506\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2785.8740 - val_loss: 2830.4287\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2770.6323 - val_loss: 2907.0083\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2756.5510 - val_loss: 2738.8372\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2735.0076 - val_loss: 2731.1765\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2711.2439 - val_loss: 2684.1938\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2699.9734 - val_loss: 2693.0208\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2685.6018 - val_loss: 2673.4648\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2662.8306 - val_loss: 2667.9634\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2649.5525 - val_loss: 2727.2178\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 4s 2ms/step - loss: 65831.5312 - val_loss: 46309.5234\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 34939.7422 - val_loss: 24107.1582\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 18665.1270 - val_loss: 13370.1377\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 10669.3604 - val_loss: 7599.3828\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 6482.1733 - val_loss: 5082.8848\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 4697.3584 - val_loss: 3989.8762\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3947.5845 - val_loss: 3577.7024\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3551.7629 - val_loss: 3350.4854\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3361.1418 - val_loss: 3198.1641\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3205.3928 - val_loss: 3061.4373\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3089.3694 - val_loss: 2961.3354\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3011.0334 - val_loss: 2947.3132\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2969.7507 - val_loss: 2867.0073\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2896.2349 - val_loss: 3020.6851\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2849.9617 - val_loss: 2816.6604\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2812.3018 - val_loss: 2822.6982\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2764.7776 - val_loss: 2827.4006\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2725.8523 - val_loss: 2799.6377\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2695.2754 - val_loss: 2779.2388\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2662.9104 - val_loss: 2798.0347\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "MSE: 2875.5796666666665\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 9950.3594 - val_loss: 3265.0298\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3198.4580 - val_loss: 2977.3196\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3095.7271 - val_loss: 2914.1152\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3040.0273 - val_loss: 2907.2114\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3000.9170 - val_loss: 2884.9131\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2953.2166 - val_loss: 2803.5000\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2909.9568 - val_loss: 2883.4526\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2900.8342 - val_loss: 2788.7957\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2859.6875 - val_loss: 2767.4260\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2821.5962 - val_loss: 2740.7043\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 2813.9905 - val_loss: 2815.7546\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 2796.8345 - val_loss: 2748.8145\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2767.1997 - val_loss: 2804.5229\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2753.5371 - val_loss: 2779.4802\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2724.9199 - val_loss: 2699.0454\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2723.6230 - val_loss: 2645.9275\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2710.1877 - val_loss: 2646.0601\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2694.1050 - val_loss: 2791.4763\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2672.9614 - val_loss: 2652.4824\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2677.8799 - val_loss: 2674.2805\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 66581.0781 - val_loss: 46533.6367\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 34912.9648 - val_loss: 23986.9902\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 18551.7715 - val_loss: 13303.3682\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 10647.3389 - val_loss: 7537.4219\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 6471.6792 - val_loss: 5193.8081\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 4694.0054 - val_loss: 4076.9893\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3900.3528 - val_loss: 3533.1426\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3504.4492 - val_loss: 3321.0791\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3290.6106 - val_loss: 3166.3474\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3150.4270 - val_loss: 3030.4473\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3046.0669 - val_loss: 2970.6677\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2972.0688 - val_loss: 2945.1526\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2912.4834 - val_loss: 2870.8040\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2865.7837 - val_loss: 2861.6777\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2818.5405 - val_loss: 2817.0906\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2777.8372 - val_loss: 2759.7041\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2735.1196 - val_loss: 2748.5825\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2694.7485 - val_loss: 2769.0605\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2669.6250 - val_loss: 2780.4387\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2643.8733 - val_loss: 2694.2515\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "282/282 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "MSE: 2820.6633333333334\n",
      "Average MSE: 2865.130866666667\n"
     ]
    }
   ],
   "source": [
    "# Extract the deep features from Model- 1 (from 2nd layer) and Model- 2 (from 2nd layer) stack the features horizontally and model it using a Support Vector Regressor.\n",
    "\n",
    "count = 5\n",
    "avg_mse = 0\n",
    "for i in range(count):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.25, random_state = 42)\n",
    "    model_1 = model1(x_train, x_val, y_train, y_val)\n",
    "    model_2 = model2(x_train, x_val, y_train, y_val)\n",
    "    x_train1 = model_1.predict(x_train)\n",
    "    x_val1 = model_1.predict(x_val)\n",
    "    x_test1 = model_1.predict(x_test)\n",
    "    x_train2 = model_2.predict(x_train)\n",
    "    x_val2 = model_2.predict(x_val)\n",
    "    x_test2 = model_2.predict(x_test)\n",
    "    x_train = np.hstack((x_train1, x_train2))\n",
    "    x_val = np.hstack((x_val1, x_val2))\n",
    "    x_test = np.hstack((x_test1, x_test2))\n",
    "    model = SVR()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.round(y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    avg_mse += mse\n",
    "    print('MSE:', mse)\n",
    "print('Average MSE:', avg_mse/count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 11557.3418 - val_loss: 3129.8757\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3202.1028 - val_loss: 2995.5012\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 3114.5168 - val_loss: 2935.2224\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 3056.4973 - val_loss: 2939.1846\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 3016.3855 - val_loss: 2844.3613\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2972.4043 - val_loss: 3005.7170\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2954.4871 - val_loss: 2939.2092\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2928.2166 - val_loss: 2907.1870\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2894.1660 - val_loss: 2807.6816\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2858.2661 - val_loss: 2743.0334\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2834.8867 - val_loss: 2733.6438\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2815.6545 - val_loss: 2813.6799\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2803.9807 - val_loss: 2718.1621\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2783.2729 - val_loss: 2816.6042\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2763.3127 - val_loss: 2687.4451\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2733.6519 - val_loss: 2692.1758\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2722.6992 - val_loss: 2691.0723\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2707.8887 - val_loss: 2729.4424\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2713.2310 - val_loss: 2676.2637\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2669.4846 - val_loss: 2671.5098\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 72639.4375 - val_loss: 55767.7383\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 44835.0234 - val_loss: 33730.2070\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 27246.3828 - val_loss: 20332.0449\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 16871.5879 - val_loss: 12980.3320\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 10759.5537 - val_loss: 8014.5767\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 7022.9595 - val_loss: 5538.8364\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 5126.4351 - val_loss: 4350.5479\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 4214.0889 - val_loss: 3748.3669\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 3748.1582 - val_loss: 3508.8459\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 3470.2751 - val_loss: 3230.0811\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 3257.7229 - val_loss: 3098.3623\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 3106.6648 - val_loss: 3010.2346\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 3004.3352 - val_loss: 2949.6387\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2931.7363 - val_loss: 2903.2646\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2864.8696 - val_loss: 2927.9819\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2817.3330 - val_loss: 2833.6243\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2765.1260 - val_loss: 2849.8396\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2738.2017 - val_loss: 2768.7876\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2709.3618 - val_loss: 2741.6062\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2666.2283 - val_loss: 2762.8892\n",
      "282/282 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "282/282 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 10939.0488 - val_loss: 3172.1624\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3192.1885 - val_loss: 2995.4351\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 3107.3428 - val_loss: 2956.1333\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 3052.4121 - val_loss: 2900.6506\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2998.3320 - val_loss: 2864.8887\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2961.7136 - val_loss: 2832.9463\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2916.2346 - val_loss: 2776.4238\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2899.7222 - val_loss: 2772.5300\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2862.4512 - val_loss: 2800.3047\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2855.2734 - val_loss: 2921.9727\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2813.1169 - val_loss: 2773.1165\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2803.0811 - val_loss: 2738.5432\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2787.9468 - val_loss: 2703.9263\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2761.1052 - val_loss: 2802.0667\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2738.2546 - val_loss: 2708.5674\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2737.4756 - val_loss: 2721.5762\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2724.9529 - val_loss: 2711.9497\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2701.5508 - val_loss: 2780.6140\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2692.3655 - val_loss: 2685.0562\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2684.5496 - val_loss: 2679.8953\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 6s 4ms/step - loss: 65814.8750 - val_loss: 46645.7773\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 35204.9453 - val_loss: 24315.4727\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 18804.1934 - val_loss: 13474.3652\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 10821.6572 - val_loss: 7652.5371\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 6536.8110 - val_loss: 5130.5205\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 4751.0479 - val_loss: 4028.8154\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3998.9810 - val_loss: 3623.7336\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3652.9465 - val_loss: 3398.1074\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3398.0947 - val_loss: 3174.8022\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 3199.1655 - val_loss: 3070.0427\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 3068.9600 - val_loss: 3016.9480\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2988.9082 - val_loss: 3030.9163\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 2915.8484 - val_loss: 2865.9043\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 2875.2849 - val_loss: 2842.9380\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2824.7908 - val_loss: 2828.6106\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2781.9841 - val_loss: 2879.3540\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2753.3164 - val_loss: 2784.2910\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2711.4333 - val_loss: 2742.8259\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2676.7749 - val_loss: 2760.0767\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2659.5769 - val_loss: 2854.3057\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 10781.7822 - val_loss: 3303.7708\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3202.1790 - val_loss: 3060.8459\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3118.4502 - val_loss: 2970.2644\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3063.0496 - val_loss: 2894.6689\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3016.3823 - val_loss: 2907.6768\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2984.9617 - val_loss: 2830.8369\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2951.2434 - val_loss: 2841.3516\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2909.4124 - val_loss: 2798.7214\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2880.1414 - val_loss: 2764.2766\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2826.8640 - val_loss: 2729.1484\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2817.5444 - val_loss: 2711.8650\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2772.0820 - val_loss: 2717.2009\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2736.8572 - val_loss: 2728.1479\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2742.3384 - val_loss: 2704.0088\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2711.8896 - val_loss: 2659.0186\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2685.2410 - val_loss: 2636.7603\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2680.7156 - val_loss: 2639.4846\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2662.1626 - val_loss: 2626.1956\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2641.1707 - val_loss: 2625.4048\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2637.1367 - val_loss: 2736.3943\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 70294.6953 - val_loss: 52806.8281\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 40022.0000 - val_loss: 28430.0449\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 22304.3066 - val_loss: 16118.9307\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 13321.0283 - val_loss: 9609.5166\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 8044.0420 - val_loss: 6150.6899\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 5495.6201 - val_loss: 4497.0005\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 4297.2871 - val_loss: 3792.8979\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3776.4019 - val_loss: 3478.3047\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3472.5854 - val_loss: 3241.9934\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3238.5984 - val_loss: 3095.3406\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3088.8330 - val_loss: 2991.7507\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2983.6807 - val_loss: 2896.9036\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2906.0740 - val_loss: 2862.7734\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2843.5950 - val_loss: 2804.3186\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2786.4507 - val_loss: 2774.5906\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2740.5554 - val_loss: 2728.1887\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2704.3684 - val_loss: 2713.1819\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2674.8513 - val_loss: 2735.7505\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2635.1685 - val_loss: 2667.7285\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2599.9814 - val_loss: 2662.4702\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 12420.7090 - val_loss: 3165.1987\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3217.2363 - val_loss: 3028.2544\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3114.7598 - val_loss: 3019.4382\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3056.6995 - val_loss: 3018.3701\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 3003.2009 - val_loss: 2856.9973\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2956.6594 - val_loss: 2861.9573\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2936.1472 - val_loss: 2867.4802\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2902.6907 - val_loss: 2777.4089\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2860.1377 - val_loss: 2842.8904\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2835.4868 - val_loss: 2752.7810\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2808.4436 - val_loss: 2738.9800\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2800.9988 - val_loss: 2752.4199\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2762.4636 - val_loss: 2765.1028\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2746.0344 - val_loss: 2716.3879\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2735.0334 - val_loss: 2718.7227\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2726.6023 - val_loss: 2678.3274\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2695.7759 - val_loss: 2705.3335\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2688.7983 - val_loss: 2677.4910\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2677.0051 - val_loss: 2691.8997\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2660.3296 - val_loss: 2728.8745\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6172 - val_loss: 87336.4844\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5469 - val_loss: 87336.4844\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5000 - val_loss: 87336.4844\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6172 - val_loss: 87336.4844\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6328 - val_loss: 87336.4844\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5859 - val_loss: 87336.4844\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6562 - val_loss: 87336.4844\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6328 - val_loss: 87336.4844\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5469 - val_loss: 87336.4844\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6016 - val_loss: 87336.4844\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5234 - val_loss: 87336.4844\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 88622.6172 - val_loss: 87336.4844\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 7s 7ms/step - loss: 13338.7236 - val_loss: 3172.3904\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 3194.4954 - val_loss: 3022.5969\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 3127.9700 - val_loss: 3007.9236\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 3044.9612 - val_loss: 2879.7576\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 3004.2278 - val_loss: 2906.0623\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2958.6125 - val_loss: 2878.4106\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 2926.0432 - val_loss: 2915.6038\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 2894.3455 - val_loss: 2836.7476\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 2872.4270 - val_loss: 2751.4663\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2844.7922 - val_loss: 2775.2534\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 2821.8948 - val_loss: 2735.2561\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 2794.2639 - val_loss: 2707.6079\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2780.1279 - val_loss: 2735.6641\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 2760.0181 - val_loss: 2713.5813\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2749.9453 - val_loss: 2677.9094\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2730.7231 - val_loss: 2701.7388\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2713.7771 - val_loss: 2819.0317\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2713.2019 - val_loss: 2662.4094\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2702.5286 - val_loss: 2682.1584\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2683.4395 - val_loss: 2646.2744\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 7s 5ms/step - loss: 65794.6406 - val_loss: 46614.2461\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 35278.9375 - val_loss: 24407.0488\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 18869.7676 - val_loss: 13506.9482\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 5s 5ms/step - loss: 10822.3545 - val_loss: 7690.3521\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 6557.6968 - val_loss: 5086.7085\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 5s 5ms/step - loss: 4742.7988 - val_loss: 4070.4006\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 3975.2097 - val_loss: 3614.0610\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 3606.5085 - val_loss: 3331.8704\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 3366.1694 - val_loss: 3167.6968\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 3197.7361 - val_loss: 3195.1526\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 3096.8467 - val_loss: 2991.8018\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 3013.9180 - val_loss: 2926.5940\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 2963.3772 - val_loss: 2942.6768\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 2899.4263 - val_loss: 2853.0276\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 5s 5ms/step - loss: 2839.7773 - val_loss: 2828.3384\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 2800.5706 - val_loss: 2851.3240\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 2756.3140 - val_loss: 2805.1057\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 2721.6050 - val_loss: 2729.4609\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2686.6519 - val_loss: 2853.1448\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2669.8044 - val_loss: 2782.6743\n",
      "282/282 [==============================] - 1s 3ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "MSE for 8 components: [2963.6483333333335]\n"
     ]
    }
   ],
   "source": [
    "# Extract the deep features from Model-1 (from 2nd layer) and Model- 2 (from 2nd layer) stack the features horizontally, reduce the dimension to either 8, 10 or 12 using principal component analysis (PCA) and model the reduced features using Support Vector Regressor. Identify the best number of reduced components of PCA.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "count = 5\n",
    "avg_mse = 0\n",
    "for i in range(count):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.25, random_state = 42)\n",
    "    model_1 = model1(x_train, x_val, y_train, y_val)\n",
    "    model_2 = model2(x_train, x_val, y_train, y_val)\n",
    "    model_1 = Model(inputs = model_1.input, outputs = model_1.get_layer(index = 2).output)\n",
    "    model_2 = Model(inputs = model_2.input, outputs = model_2.get_layer(index = 2).output)\n",
    "    x_train1 = model_1.predict(x_train)\n",
    "    x_val1 = model_1.predict(x_val)\n",
    "    x_test1 = model_1.predict(x_test)\n",
    "    x_train2 = model_2.predict(x_train)\n",
    "    x_val2 = model_2.predict(x_val)\n",
    "    x_test2 = model_2.predict(x_test)\n",
    "    x_train = np.hstack((x_train1, x_train2))\n",
    "    x_val = np.hstack((x_val1, x_val2))\n",
    "    x_test = np.hstack((x_test1, x_test2))\n",
    "    mse = []\n",
    "    \n",
    "    pca = PCA(n_components = 8)\n",
    "    pca.fit(x_train)\n",
    "    x_train_pca = pca.transform(x_train)\n",
    "    x_val_pca = pca.transform(x_val)\n",
    "    x_test_pca = pca.transform(x_test)\n",
    "    model = SVR()\n",
    "    model.fit(x_train_pca, y_train)\n",
    "    y_pred = model.predict(x_test_pca)\n",
    "    y_pred = np.round(y_pred)\n",
    "    mse.append(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('MSE for 8 components:', mse)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw conclusions on the best model among the above four models for predicting the Delhi AirQualityIndex.\n",
    "Average MSE for model 1 : 2833.979866666667\n",
    "Average MSE for model 2 : 4231.987533333333\n",
    "Average MSE for model 3 : 2865.130866666667\n",
    "Average MSE for model 4 : 2963.6483333333335\n",
    "    \n",
    "The best model is Model 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
